package de.uni_mannheim.informatik.dws.melt.matching_ml.python.nlptransformers;

import de.uni_mannheim.informatik.dws.melt.matching_base.FileUtil;
import de.uni_mannheim.informatik.dws.melt.matching_base.Filter;
import de.uni_mannheim.informatik.dws.melt.yet_another_alignment_api.Alignment;
import de.uni_mannheim.informatik.dws.melt.yet_another_alignment_api.Correspondence;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileOutputStream;
import java.io.OutputStreamWriter;
import java.io.Writer;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.text.StringEscapeUtils;
import org.apache.jena.ontology.OntModel;
import org.apache.jena.rdf.model.Resource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import de.uni_mannheim.informatik.dws.melt.matching_jena.TextExtractor;
import de.uni_mannheim.informatik.dws.melt.matching_jena.TextExtractorMap;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

/**
 * This filter asks a LLM if a given correspondence is correct or not.
 * It has no information about the other correspondences and each correspondence becomes a prediction example for the LLM.
 * It will add the corresponding confidence to the correspondence such that a filtering afterwards is possible.
 */
public class LLMBinaryFilter extends LLMBase implements Filter {

    private static final String NEWLINE = System.getProperty("line.separator");
    
    private static final Logger LOGGER = LoggerFactory.getLogger(LLMBinaryFilter.class);
        
    /**
     * Set of positive words to use. Default is "yes" (and some variations of it (generated with {@link #includeMoreVariations(java.util.Set)})
     */
    protected Set<String> positiveWords;
    
    /**
     * Set of negative words to use. Default is "no" (and some variations of it (generated with {@link #includeMoreVariations(java.util.Set)})
     */
    protected Set<String> negativeWords;
        
    
    /**
     * Constructor with all required parameters and default values for optional parameters (can be changed by setters).
     * It uses the systems default tmp dir to store the files with texts generated from the knowledge graphs.
     * Pytorch is used instead of tensorflow and all visible GPUs are used for prediction.
     * @param extractor the extractor to select which text for each resource should be used.
     * @param modelName the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be absolute. 
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     * @param promt The promt to use for the LLM. Use {left} and {right} to insert the text representation of the left and right concept.
     */
    public LLMBinaryFilter(TextExtractorMap extractor, String modelName, String promt) {
        super(extractor, modelName, promt);
        this.positiveWords = includeMoreVariations("yes", "true");
        this.negativeWords = includeMoreVariations("no", "false");
    }
    
    /**
     * Constructor with all required parameters and default values for optional parameters (can be changed by setters).
     * It uses the systems default tmp dir to store the files with texts generated from the knowledge graphs.
     * Pytorch is used instead of tensorflow and all visible GPUs are used for prediction.
     * @param extractor the extractor to select which text for each resource should be used.
     * @param modelName the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be absolute. 
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     * @param promt The promt to use for the LLM. Use {left} and {right} to insert the text representation of the left and right concept.
     */
    public LLMBinaryFilter(TextExtractor extractor, String modelName, String promt) {
        this(TextExtractorMap.wrapTextExtractor(extractor), modelName, promt);
    }
    
    @Override
    public Alignment match(OntModel source, OntModel target, Alignment inputAlignment, Properties properties) throws Exception {
        File inputFile = FileUtil.createFileWithRandomNumber("alignment_llm_predict", ".txt");
        Map<Correspondence, List<Integer>> map;
        try{
            map = createPredictionFile(source, target, inputAlignment, inputFile, false);
        }catch (IOException ex) {
            LOGGER.warn("Could not write text to prediction file. Return unmodified input alignment.", ex);
            inputFile.delete();
            return inputAlignment;
        }
        try {
            if(map.isEmpty()){
                LOGGER.warn("No correspondences have enough text to be processed (the input alignment has {} " +
                        "correspondences) - the input alignment is returned unchanged.", inputAlignment.size());
                return inputAlignment;
            }
            
            LOGGER.info("Run prediction");
            List<List<Double>> confidenceList = predictConfidences(inputFile, getWordsToDetect());
            LOGGER.info("Finished prediction");

            for(Entry<Correspondence, List<Integer>> correspondenceToLineNumber : map.entrySet()){
                double max = 0.0;
                for(Integer lineNumber : correspondenceToLineNumber.getValue()){
                    List<Double> conf = confidenceList.get(lineNumber);
                    if(conf == null){
                        throw new IllegalArgumentException("Could not find a confidence for a given correspondence.");
                    }
                    //convert to confidence:
                    if(conf.size() < 2){
                        throw new IllegalArgumentException("Too less confidence values for one correspondence.");
                    }
                    double yes_confidence = conf.get(0); // positive words are at position 0 - see getWordsToDetect function
                    double no_confidence = conf.get(1);  // negative words are at position 1 - see getWordsToDetect function
                    double final_conf = yes_confidence / (yes_confidence + no_confidence);
                    
                    if(final_conf > max)
                        max = final_conf;
                }
                correspondenceToLineNumber.getKey().addAdditionalConfidence(this.getClass(), max);
            }
        } finally {
            inputFile.delete();
        }
        return inputAlignment;
    }

    /**
     * Create the prediction file which is a CSV file with two columns.The first column is the text from the left resource and the second column is the text from the right resource.
     * @param source The source model
     * @param target The target model
     * @param predictionAlignment the alignment to process. All correspondences which have enough text are used.
     * @param outputFile the csv file to which the output should be written to.
     * @param append if true, then the training alignment is append to the given file.
     * @return the map which maps the the correspondence to (possibly multiple) row numbers.
     * In case of multipleTextsToMultipleExamples is set to true, multiple rows can correspond to one correspondence,
     * because each text (e.g. label, comment etc) of the two resources is used as an example.
     * @throws IOException in case the writing fails.
     */
    public Map<Correspondence, List<Integer>> createPredictionFile(OntModel source, OntModel target, Alignment predictionAlignment, File outputFile, boolean append) throws IOException {
        Map<Correspondence, List<Integer>> map = new HashMap<>();
        int i = 0;
        try (Writer writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(outputFile, append), StandardCharsets.UTF_8))){
            Map<Resource,Map<String, Set<String>>> cache = new HashMap<>();
            for(Correspondence c : predictionAlignment){
                c.addAdditionalConfidence(this.getClass(), 0.0d); // initialize it
                
                Map<String, Set<String>> sourceTexts = getTextualRepresentation(source.getResource(c.getEntityOne()), cache);
                Map<String, Set<String>> targetTexts = getTextualRepresentation(target.getResource(c.getEntityTwo()), cache);

                for(Entry<String, Set<String>> textLeftGroup : sourceTexts.entrySet()){
                    for(String textRight : targetTexts.get(textLeftGroup.getKey())){
                        if(StringUtils.isBlank(textRight)){
                            continue;
                        }
                        for(String textLeft : textLeftGroup.getValue()){
                            if(StringUtils.isBlank(textLeft)){
                                continue;
                            }
                            writer.write(StringEscapeUtils.escapeCsv(textLeft) + "," + StringEscapeUtils.escapeCsv(textRight) + NEWLINE);
                            map.computeIfAbsent(c, __-> new ArrayList<>()).add(i);
                            i++;
                        }
                    }
                }
            }
        }
        LOGGER.info("Wrote {} examples to prediction file {}", i, outputFile);
        return map;
    }

    public Set<String> getPositiveWords() {
        return positiveWords;
    }

    public void setPositiveWords(Set<String> positiveWords) {
        if(positiveWords == null)
            throw new IllegalArgumentException("Positive words cannot be null.");
        this.positiveWords = positiveWords;
    }
    
    public void addPositiveWord(String positiveWord){
        this.positiveWords.add(positiveWord);
    }

    public Set<String> getNegativeWords() {
        return negativeWords;
    }

    public void setNegativeWords(Set<String> negativeWords) {
        if(negativeWords == null)
            throw new IllegalArgumentException("Negative words cannot be null.");
        this.negativeWords = negativeWords;
    }
    
    public void addNegativeWord(String negativeWord){
        this.negativeWords.add(negativeWord);
    }
    
    
    protected List<Set<String>> getWordsToDetect() {
        List<Set<String>> list = new ArrayList<>(2);
        list.add(this.positiveWords); // positive words are at position 0 - see match function
        list.add(this.negativeWords); // negative words are at position 1 - see match function
        return list;
    }

}
