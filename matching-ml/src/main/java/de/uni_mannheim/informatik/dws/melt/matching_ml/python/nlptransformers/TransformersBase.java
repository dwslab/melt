package de.uni_mannheim.informatik.dws.melt.matching_ml.python.nlptransformers;

import de.uni_mannheim.informatik.dws.melt.matching_base.FileUtil;
import de.uni_mannheim.informatik.dws.melt.matching_jena.MatcherYAAAJena;
import java.io.File;
import de.uni_mannheim.informatik.dws.melt.matching_jena.TextExtractor;
import java.util.Arrays;
import java.util.stream.Collectors;

/**
 * This is a base class for all Tranformers.
 * It just contains some variables and getter and setters.
 */
public abstract class TransformersBase extends MatcherYAAAJena {
    
    protected TextExtractor extractor;
    protected String modelName;
    
    protected TransformersTrainerArguments trainingArguments;
    protected File tmpDir;
    protected boolean usingTensorflow;
    protected String cudaVisibleDevices;
    protected File transformersCache;
    protected TransformersMultiProcessing multiProcessing;

    /**
     * Constructor with all required parameters.
     * @param extractor the extractor to select which text for each resource should be used.
     * @param modelName the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be abolute. 
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     */
    public TransformersBase(TextExtractor extractor, String modelName) {
        this.extractor = extractor;
        this.modelName = modelName;
        
        //set useful defaults
        this.trainingArguments = new TransformersTrainerArguments();
        this.tmpDir = FileUtil.SYSTEM_TMP_FOLDER;
        this.usingTensorflow = false;
        this.cudaVisibleDevices = ""; //use all GPUs
        this.transformersCache = null; //use default
        this.multiProcessing = TransformersMultiProcessing.DEFAULT_MULTI_PROCESS;
    }
    
    /**
     * Returns the text extractor which extracts text from a given resource. This is the text which represents a resource.
     * @return the text extractor
     */
    public TextExtractor getExtractor() {
        return extractor;
    }

    /**
     * Sets the extractor which computes the text from a given resource. 
     * This is the text which represents a resource.
     * @param extractor the text extractor
     */
    public void setExtractor(TextExtractor extractor) {
        this.extractor = extractor;
    }

    /**
     * Returns the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>)
     * @return the model name as a string
     */
    public String getModelName() {
        return modelName;
    }
    
    /**
     * Sets the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be abolute. 
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     * @param modelName the model name as a string
     */
    public void setModelName(String modelName) {
        this.modelName = modelName;
    }

    

    /**
     * Returns the training arguments of the huggingface trainer.
     * Any of the training arguments can be used. For further documentation, see{@link TransformersTrainerArguments}
     * @return the transformer location
     */
    public TransformersTrainerArguments getTrainingArguments() {
        return trainingArguments;
    }

    /**
     * Sets the training arguments of the huggingface trainer.
     * Any of the training arguments can be used. For further documentation, see{@link TransformersTrainerArguments}
     * @param configuration the trainer configuration
     */
    public void setTrainingArguments(TransformersTrainerArguments configuration) {
        this.trainingArguments = configuration;
    }

    /**
     * Returns the tmp directory used by the matcher.
     * In this folder the file with all texts from the ont models are stored.
     * Usually the created files are removed automatically.
     * @return the tmp directory
     */
    public File getTmpDir() {
        return tmpDir;
    }

    /**
     * Sets the tmp directory used by the matcher.
     * In this folder the file with all texts from the knowledge graph are stored.
     * Usually the created files are removed automatically.
     * Default is the systems tmp folder.
     * @param tmpDir the tmp dir to be used.
     */
    public void setTmpDir(File tmpDir) {
        if(tmpDir == null){
            throw new IllegalArgumentException("TmpDir should not be not to null.");
        }
        if(tmpDir.exists() == false){
            tmpDir.mkdirs();
        }
        this.tmpDir = tmpDir;
    }
   
    /**
     * Returns a boolean value if tensorflow is used to train the model.
     * If true, the models are run with tensorflow. If false, pytorch is used.
     * @return true, if tensorflowis used. false, if pytorch is used.
     */
    public boolean isUsingTensorflow() {
        return usingTensorflow;
    }

    /**
     * Sets the boolean value if tensorflow is used.
     * If set to false, true, pytorch is used.
     * @param usingTensorflow true to use tensorflow and false to use pytorch.
     */
    public void setUsingTensorflow(boolean usingTensorflow) {
        this.usingTensorflow = usingTensorflow;
    }

    /**
     * Returns a string which is set to the environment variable CUDA_VISIBLE_DEVICES to select on
     * which GPU the process should run. If null or empty, the default is used (all available GPUs).
     * @return the variable CUDA_VISIBLE_DEVICES
     */
    public String getCudaVisibleDevices() {
        return cudaVisibleDevices;
    }

    /**
     * Sets the environment variable CUDA_VISIBLE_DEVICES to select on
     * which GPUs the process should run. If null or the string is empty, the default is used (all available GPUs).
     * If multiple GPUs can be used, then the values should be comma separated.
     * Example: "0" to use only the first GPU. "1,3" to use the second and fourth GPU.
     * The use of {@link #setCudaVisibleDevices(int...) } is preffered because it is more type safe.
     * @param cudaVisibleDevices the string which is set to the environment variable CUDA_VISIBLE_DEVICES
     */
    public void setCudaVisibleDevices(String cudaVisibleDevices) {
        this.cudaVisibleDevices = cudaVisibleDevices.trim();
    }
    
    /**
     * Sets the environment variable CUDA_VISIBLE_DEVICES to select on
     * which GPUs the process should run. If no values are provided, then all available GPUs are used.
     * If multiple GPUs should be used, then provide the values one after the other.
     * All indices are zero based. So call {@code setCudaVisibleDevices(0,1)} to use the first two GPUs.
     * @param cudaVisibleDevices the integer numbers which refers to the GPUs which should be used.
     */
    public void setCudaVisibleDevices(int... cudaVisibleDevices) {
        this.cudaVisibleDevices = Arrays.stream(cudaVisibleDevices).mapToObj(String::valueOf).collect(Collectors.joining(","));
    }

    /**
     * Returns the cache folder where the pretrained transformers models are stored.
     * If set to null, the default locations is used (<a href="https://huggingface.co/transformers/installation.html#caching-models">
     * which is usually ~/.cache/huggingface/transformers/</a>).
     * @return the transformers cache folder.
     */
    public File getTransformersCache() {
        return transformersCache;
    }

    /**
     * Sets the cache folder where the pretrained transformers models are stored.
     * If set to null, the default locations is used (<a href="https://huggingface.co/transformers/installation.html#caching-models">
     * which is usually ~/.cache/huggingface/transformers/</a>).
     * This setter is usefull, if the default location does not have enough space available.
     * Then just set it to a folder which have a lot of free space.
     * @param transformersCache the transformers cache folder
     */
    public void setTransformersCache(File transformersCache) {
        if(transformersCache == null || transformersCache.isDirectory()){
            this.transformersCache = transformersCache; //null sets the default value
        } else{
            throw new IllegalArgumentException("transformersCache is not a directory or is not existent.");
        }
    }

    /**
     * Returns the multiprocessing value of the transformer.
     * The transformers library may not free all memory from GPU.
     * Thus the prediction and training are wrapped in an external process.
     * This enum defines how the process is started and if multiprocessing should be used at all.
     * Default is to use the system dependent default.
     * @return the enum which represent the multi process starting method.
     */
    public TransformersMultiProcessing getMultiProcessing() {
        return multiProcessing;
    }
    
    /**
     * Sets the multiprocessing value of the transformer.
     * The transformers library may not free all memory from GPU.
     * Thus the prediction and training are wrapped in an external process.
     * This enum defines how the process is started and if multiprocessing should be used at all.
     * Default is to use the system dependent default.
     * @param multiProcessing the enum which represent the multi process starting method.
     */
    public void setMultiProcessing(TransformersMultiProcessing multiProcessing) {
        this.multiProcessing = multiProcessing;
    }
}
