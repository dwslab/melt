package de.uni_mannheim.informatik.dws.melt.matching_ml.python.nlptransformers;

import de.uni_mannheim.informatik.dws.melt.matching_base.FileUtil;
import de.uni_mannheim.informatik.dws.melt.matching_jena.MatcherYAAAJena;
import java.io.File;
import de.uni_mannheim.informatik.dws.melt.matching_jena.TextExtractor;
import de.uni_mannheim.informatik.dws.melt.matching_jena.TextExtractorMap;
import java.io.BufferedWriter;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.PriorityQueue;
import java.util.Set;
import java.util.StringJoiner;
import java.util.regex.Pattern;
import java.util.stream.Collectors;
import org.apache.commons.csv.CSVFormat;
import org.apache.commons.csv.CSVParser;
import org.apache.commons.csv.CSVRecord;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.text.StringEscapeUtils;
import org.apache.jena.rdf.model.Resource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * This is a base class for all Transformers.
 * It just contains some variables and getter and setters.
 */
public abstract class TransformersBase extends MatcherYAAAJena {


    private static final Logger LOGGER = LoggerFactory.getLogger(TransformersBase.class);

    protected TextExtractorMap extractor;
    protected String modelName;
    
    protected TransformersArguments trainingArguments;
    protected boolean usingTensorflow;
    protected String cudaVisibleDevices;
    protected File transformersCache;
    protected TransformersMultiProcessing multiProcessing;
    protected boolean multipleTextsToMultipleExamples;

    /**
     * Constructor with all required parameters.
     * @param extractor the extractor to select which text for each resource should be used.
     * @param modelName the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be absolute.
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     */
    public TransformersBase(TextExtractorMap extractor, String modelName) {
        this.extractor = extractor;
        this.modelName = modelName;
        
        //set useful defaults
        this.trainingArguments = new TransformersArguments();
        this.usingTensorflow = false;
        this.cudaVisibleDevices = ""; //use all GPUs
        this.transformersCache = null; //use default
        this.multiProcessing = TransformersMultiProcessing.SPAWN;
        this.multipleTextsToMultipleExamples = false;
    }
    
    /**
     * Constructor with all required parameters.
     * @param extractor the extractor to select which text for each resource should be used.
     * @param modelName the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be absolute.
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     */
    public TransformersBase(TextExtractor extractor, String modelName) {
        this(TextExtractorMap.wrapTextExtractor(extractor), modelName);
    }
    
    /**
     * Returns the text extractor which extracts text from a given resource. This is the text which represents a resource.
     * @return the text extractor
     */
    public TextExtractor getExtractor() {
        return TextExtractor.wrapTextExtractorMap(extractor);
    }
    
    /**
     * Returns the text extractor which extracts text from a given resource. This is the text which represents a resource.
     * @return the text extractor
     */
    public TextExtractorMap getExtractorMap() {
        return extractor;
    }

    /**
     * Sets the extractor which computes the text from a given resource. 
     * This is the text which represents a resource.
     * @param extractor the text extractor
     */
    public void setExtractor(TextExtractor extractor) {
        this.extractor = TextExtractorMap.wrapTextExtractor(extractor);
    }
    
    /**
     * Sets the extractor which computes the text from a given resource.
     * This is the map variant which also includes the given keys in the map when MultipleTextsToMultipleExamples is set to true.
     * @param extractorMap the text extractormap
     */
    public void setExtractorMap(TextExtractorMap extractorMap) {
        this.extractor = extractorMap;
    }

    /**
     * Returns the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>)
     * @return the model name as a string
     */
    public String getModelName() {
        return modelName;
    }
    
    /**
     * Sets the model name which can be a model id (a hosted model on huggingface.co) or a path to a directory containing a model and tokenizer
     * (<a href="https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained">
     * see first parameter pretrained_model_name_or_path of the from_pretrained
     * function in huggingface library</a>). In case of a path, it should be abolute. 
     * The path can be generated by e.g. {@link FileUtil#getCanonicalPathIfPossible(java.io.File) }
     * @param modelName the model name as a string
     */
    public void setModelName(String modelName) {
        this.modelName = modelName;
    }

    /**
     * Returns the training arguments of the huggingface trainer.
     * Any of the training arguments which are <a href="https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments">listed on the documentation</a>
     * can be used.
     * @return the transformer location
     */
    public TransformersArguments getTrainingArguments() {
        return trainingArguments;
    }

    /**
     * Sets the training arguments of the huggingface trainer.
     * Any of the training arguments which are <a href="https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments">listed on the documentation</a>
     * can be used.
     * @param configuration the trainer configuration
     */
    public void setTrainingArguments(TransformersArguments configuration) {
        if(configuration == null)
            throw new IllegalArgumentException("training arguments cannot be set to null");
        this.trainingArguments = configuration;
    }
    
    /**
     * Adds a training argument for the transformers trainer.
     * Any of the training arguments which are <a href="https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments">listed on the documentation</a>
     * can be used.
     * @param key The key of the training argument like warmup_ratio
     * @param value the corresponding value like 0.2
     */
    public void addTrainingArgument(String key, Object value){
        this.trainingArguments.addParameter(key, value);
    }

    /**
     * Returns a boolean value if tensorflow is used to train the model.
     * If true, the models are run with tensorflow. If false, pytorch is used.
     * @return true, if tensorflow is used. false, if pytorch is used.
     */
    public boolean isUsingTensorflow() {
        return usingTensorflow;
    }

    /**
     * Sets the boolean value if tensorflow is used.
     * If set to false, true, pytorch is used.
     * @param usingTensorflow true to use tensorflow and false to use pytorch.
     */
    public void setUsingTensorflow(boolean usingTensorflow) {
        this.usingTensorflow = usingTensorflow;
    }
    
    protected String getCudaVisibleDevicesButOnlyOneGPU(){
        String gpus = this.getCudaVisibleDevices();
        if(gpus == null) // this means use all available.
            return "0"; //then we select only the first one
        gpus = gpus.trim();
        if(gpus.isEmpty())
            return "0"; // same as above
        String[] array = gpus.split(",");
        return array[0]; // one element is always contained
    }

    /**
     * Returns a string which is set to the environment variable CUDA_VISIBLE_DEVICES to select on
     * which GPU the process should run. If null or empty, the default is used (all available GPUs).
     * @return the variable CUDA_VISIBLE_DEVICES
     */
    public String getCudaVisibleDevices() {
        return cudaVisibleDevices;
    }

    /**
     * Sets the environment variable CUDA_VISIBLE_DEVICES to select on
     * which GPUs the process should run. If null or the string is empty, the default is used (all available GPUs).
     * If multiple GPUs can be used, then the values should be comma separated.
     * Example: "0" to use only the first GPU. "1,3" to use the second and fourth GPU.
     * The use of {@link #setCudaVisibleDevices(int...) } is preffered because it is more type safe.
     * @param cudaVisibleDevices the string which is set to the environment variable CUDA_VISIBLE_DEVICES
     */
    public void setCudaVisibleDevices(String cudaVisibleDevices) {
        this.cudaVisibleDevices = cudaVisibleDevices.trim();
    }
    
    /**
     * Sets the environment variable CUDA_VISIBLE_DEVICES to select on
     * which GPUs the process should run. If no values are provided, then all available GPUs are used.
     * If multiple GPUs should be used, then provide the values one after the other.
     * All indices are zero based. So call {@code setCudaVisibleDevices(0,1)} to use the first two GPUs.
     * @param cudaVisibleDevices the integer numbers which refers to the GPUs which should be used.
     */
    public void setCudaVisibleDevices(int... cudaVisibleDevices) {
        this.cudaVisibleDevices = Arrays.stream(cudaVisibleDevices).mapToObj(String::valueOf).collect(Collectors.joining(","));
    }

    /**
     * Returns the cache folder where the pretrained transformers models are stored.
     * If set to null, the default locations is used (<a href="https://huggingface.co/transformers/installation.html#caching-models">
     * which is usually ~/.cache/huggingface/transformers/</a>).
     * @return the transformers cache folder.
     */
    public File getTransformersCache() {
        return transformersCache;
    }

    /**
     * Sets the cache folder where the pretrained transformers models are stored.
     * If set to null, the default locations is used (<a href="https://huggingface.co/transformers/installation.html#caching-models">
     * which is usually ~/.cache/huggingface/transformers/</a>).
     * This setter is useful, if the default location does not have enough space available.
     * Then just set it to a folder which have a lot of free space.
     * @param transformersCache The transformers cache folder.
     */
    public void setTransformersCache(File transformersCache) {
        if(transformersCache == null || transformersCache.isDirectory()) {
            this.transformersCache = transformersCache; //null sets the default value
        } else {
            throw new IllegalArgumentException("transformersCache is not a directory or does not exist.");
        }
    }

    /**
     * Returns the multiprocessing value of the transformer.
     * The transformers library may not free all memory from GPU.
     * Thus the prediction and training are wrapped in an external process.
     * This enum defines how the process is started and if multiprocessing should be used at all.
     * Default is to use the system dependent default.
     * @return the enum which represent the multi process starting method.
     */
    public TransformersMultiProcessing getMultiProcessing() {
        return multiProcessing;
    }
    
    /**
     * Sets the multiprocessing value of the transformer.
     * The transformers library may not free all memory from GPU.
     * Thus the prediction and training are wrapped in an external process.
     * This enum defines how the process is started and if multiprocessing should be used at all.
     * Default is to use the system dependent default.
     * @param multiProcessing the enum which represent the multi process starting method.
     */
    public void setMultiProcessing(TransformersMultiProcessing multiProcessing) {
        this.multiProcessing = multiProcessing;
    }
    
    /**
     * Enable or disable the mixed precision training.
     * This will optimize the runtime of training and 
     * @param mpt true to enable mixed precision training
     */
    public void setOptimizeForMixedPrecisionTraining(boolean mpt){
        this.trainingArguments.addParameter("fp16", mpt);
    }
    
    /**
     * Returns the value if mixed precision training is enabled or diabled.
     * @return true if mixed precision training is enabled.
     */
    public boolean isOptimizeForMixedPrecisionTraining(){
        Object o = this.trainingArguments.getParameterOrDefault("fp16", false);
        if(o instanceof Boolean){
            return (boolean) o;
        }else{
            LOGGER.warn("parameter fp16 is not a boolean value");
            return false;
        }
    }

    /**
     * Returns the value if all texts returned by the text extractor are used separately to generate the examples.
     * Otherwise it will concatenate all texts together to form one example(the default).
     * This should be only enabled when the extractor does not return many texts because otherwise a lot of examples are produced.
     * @return true, if generation of multiple examples is enabled
     */
    public boolean isMultipleTextsToMultipleExamples() {
        return multipleTextsToMultipleExamples;
    }

    /**
     * Is set to true, then all texts returned by the text extractor are used separately to generate the examples.
     * Otherwise it will concatenate all texts together to form one example(the default).
     * This should be only enabled when the extractor does not return many texts because otherwise a lot of examples are produced.
     * @param multipleTextsToMultipleExamples true, to enable the generation of multiple examples.
     */
    public void setMultipleTextsToMultipleExamples(boolean multipleTextsToMultipleExamples) {
        this.multipleTextsToMultipleExamples = multipleTextsToMultipleExamples;
    }
    
    
    protected Map<String, Set<String>> getTextualRepresentation(Resource r, Map<Resource,Map<String, Set<String>>> cache){
        Map<String, Set<String>> cacheResult = cache.get(r);
        if(cacheResult != null)
            return cacheResult;
        Map<String, Set<String>> texts = new HashMap<>();
        if(this.multipleTextsToMultipleExamples){
            texts = this.extractor.extract(r);
        }else{
            StringBuilder sb = new StringBuilder();
            for(Map.Entry<String, Set<String>> groupedText : this.extractor.extract(r).entrySet()){
                for(String text : groupedText.getValue()){
                    sb.append(text.trim()).append(" ");
                }
            }
            String extractedText = sb.toString();
            if(!StringUtils.isBlank(extractedText)){
                texts.put("OneText", new HashSet<>(Arrays.asList(extractedText)));
            }
        }
        cache.put(r, texts);
        return texts;
    }
    
        private static final String LOREM_IPSUM = StringEscapeUtils.escapeCsv(
"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt " +
"ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo " +
"dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor " +
"sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor " +
"invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et " +
"justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum " +
"dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod " +
"tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam " +
"et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem " +
"ipsum dolor sit amet. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie " +
"consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio " +
"dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. " +
"Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt " +
"ut laoreet dolore magna aliquam erat volutpat. Ut wisi enim ad minim veniam, quis nostrud exerci " +
"tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. Duis autem vel eum " +
"iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat " +
"nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum " +
"zzril delenit augue duis dolore te feugait nulla facilisi. Nam liber tempor cum soluta nobis " +
"eleifend option congue nihil imperdiet doming id quod mazim placerat facer.");
    private static final Pattern SPLIT_WORDS = Pattern.compile("\\s+");
        
    protected List<String> getExamplesForBatchSizeOptimization(File trainingFile, int numberOfExamples, BatchSizeOptimization optimization) {        
        switch(optimization){
            case USE_LONGEST_TEXTS_PESSIMISTIC:
            case USE_LONGEST_TEXTS:{
                return getExamplesForBatchSizeOptimizationGivenComparator(trainingFile, numberOfExamples, new Comparator<List<String>>() {
                    @Override
                    public int compare(List<String> o1, List<String> o2) {
                        int lengthOne = o1.stream().mapToInt(s -> s.length()).sum();
                        int lengthTwo = o2.stream().mapToInt(s -> s.length()).sum();
                        return Integer.compare(lengthOne, lengthTwo);
                    }
                });
            }            
            case USE_MAX_WORDS:{
                return getExamplesForBatchSizeOptimizationGivenComparator(trainingFile, numberOfExamples, new Comparator<List<String>>() {
                    @Override
                    public int compare(List<String> o1, List<String> o2) {
                        int lengthOne = o1.stream().mapToInt(s -> SPLIT_WORDS.split(s).length).sum();
                        int lengthTwo = o2.stream().mapToInt(s -> SPLIT_WORDS.split(s).length).sum();
                        return Integer.compare(lengthOne, lengthTwo);
                    }
                });
            }
            case USE_THEORETICAL_MAX:{
                return createLoremIpsum(numberOfExamples);
            }
            default:
                throw new UnsupportedOperationException("batchSizeOptimization not implemented");
        }
    }
    /**
     * Creates examples for the batch size optimization which takes care of the csv format (in case one entity is distributed over multiple lines.
     * @param trainingFile the trainign file to read from
     * @param numberOfExamples number of examples to be returned
     * @param comparer the compararer (shoud fulfill the comparer interface -1 if first is smaller than second etc)
     * @return the largest elements in this file as a list of strings (these are already csv formatted).
     */
    private static List<String> getExamplesForBatchSizeOptimizationGivenComparator(File trainingFile, int numberOfExamples, Comparator<List<String>> comparer){
        PriorityQueue<List<String>> minHeap = new PriorityQueue<>(numberOfExamples, comparer);
        try(CSVParser csvParser = CSVFormat.DEFAULT.parse(new InputStreamReader(new FileInputStream(trainingFile), StandardCharsets.UTF_8))){
            for (CSVRecord record : csvParser) {
                List<String> example = new ArrayList<>();
                for(String x : record){
                    example.add(x);
                }

                if(minHeap.size() < numberOfExamples){
                    minHeap.add(example);
                }else{
                    List<String> l = minHeap.peek();
                    if (comparer.compare(minHeap.peek(), example) < 0){
                        minHeap.poll();
                        minHeap.add(example);
                    }
                }
            }
            List<List<String>> sortedHeap = new ArrayList<>(minHeap);
            sortedHeap.sort(comparer.reversed());
            
            List<String> returnList = new ArrayList<>();
            for(List<String> record : sortedHeap){
                StringJoiner sj = new StringJoiner(",");
                for(String x : record){
                    sj.add(StringEscapeUtils.escapeCsv(x));
                }
                returnList.add(sj.toString());
            }
            return returnList;
        } catch (IOException ex) {
            LOGGER.warn("Could not read file for determining best BatchSize. Fallback to USE_THEORETICAL_MAX using lorem ipsum text.", ex);
            return createLoremIpsum(numberOfExamples);
        }
    }
    
    
    private static List<String> createLoremIpsum(int numberOfExamples){
        List<String> list = new ArrayList<>(numberOfExamples);
        for(int i=0; i<numberOfExamples; i++){
            //escape csv is already done when initializing LOREM_IPSUM
            list.add(LOREM_IPSUM + "," + LOREM_IPSUM + ",1");
        }
        return list;
    }
    protected boolean writeExamplesToFile(List<String> list, File destination, int numberOfExamples) throws IOException{
        int i = 1;
        try(BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(destination), StandardCharsets.UTF_8))){
            for(String text : list){
                writer.write(text);
                writer.newLine();
                if(i >= numberOfExamples){
                    break;
                }
                i++;
            }
        }
        return i >= numberOfExamples;
    }
}

/*
//use longest texts:
Comparator<String> comparer = (String o1, String o2) -> Integer.compare(o1.length(), o2.length());

PriorityQueue<String> minHeap = new PriorityQueue<>(numberOfExamples, comparer);
try(CSVParser csvParser = CSVFormat.DEFAULT.parse(new InputStreamReader(new FileInputStream(trainingFile), StandardCharsets.UTF_8))){
    for (CSVRecord record : csvParser) {
        StringJoiner sj = new StringJoiner(",");
        for(String x : record){
            sj.add(StringEscapeUtils.escapeCsv(x));
        }
        String line = sj.toString();

        if(minHeap.size() < numberOfExamples){
            minHeap.add(line);
        }else{
            if (minHeap.peek().length() < line.length()){
                minHeap.poll();
                minHeap.add(line);
            }
        }
    }
    List<String> returnList = new ArrayList<>(minHeap);
    returnList.sort(comparer.reversed());
    return returnList;

} catch (IOException ex) {
    LOGGER.warn("Could not read file for determining best BatchSize. Fallback to USE_THEORETICAL_MAX using lorem ipsum text.", ex);
    return createLoremIpsum(numberOfExamples);
}
*/